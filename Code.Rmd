---
title: "Proj 2"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

* Import data
```{r}
image1 = read.delim(file = "image_data/image1.txt", header = FALSE, sep = "")
colnames(image1) = c("y_coord", "x_coord", "expert_label", "NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")
image2 = read.delim(file = "image_data/image2.txt", header = FALSE, sep = "")
colnames(image2) = c("y_coord", "x_coord", "expert_label", "NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")
image3 = read.delim(file = "image_data/image3.txt", header = FALSE, sep = "")
colnames(image3) = c("y_coord", "x_coord", "expert_label", "NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")
all = rbind(image1, image2, image3)
```

## Problem 1
* 1(b)
```{r}
nrow(image1)
sum(image1$expert_label == 1) / nrow(image1)
sum(image1$expert_label == -1) / nrow(image1)
sum(image1$expert_label == 0) / nrow(image1)
```
For image1, there are 115229 data points. We calculate % of pixels for the different classes: 17.77% classified as cloud, 43.78% as not cloud and 38.46% as unlabeled.
```{r}
nrow(image2)
sum(image2$expert_label == 1) / nrow(image2)
sum(image2$expert_label == -1) / nrow(image2)
sum(image2$expert_label == 0) / nrow(image2)
```
For image2, there are 115110 data points. We calculate % of pixels for the different classes: 34.11% classified as cloud, 37.25% as not cloud and 28.64% as unlabeled.
```{r}
nrow(image3)
sum(image3$expert_label == 1) / nrow(image3)
sum(image3$expert_label == -1) / nrow(image3)
sum(image3$expert_label == 0) / nrow(image3)
```
For image3, there are 115217 data points. We calculate % of pixels for the different classes: 18.44% classified as cloud, 29.29% as not cloud and 52.27% as unlabeled.
```{r}
nrow(all)
sum(all$expert_label == 1) / nrow(all)
sum(all$expert_label == -1) / nrow(all)
sum(all$expert_label == 0) / nrow(all)
```
After we combined three image data sets, there are 345556 data points. We calculate % of pixels for the different classes: 23.43% classified as cloud, 36.78% as not cloud and 39.79% as unlabeled.

```{r}
library(ggplot2)
label = image1$expert_label
label[label == 1] = "cloud"
label[label == -1] = "not cloud"
label[label == 0] = "unlabeled"
image1_plot = data.frame(x = image1$x_coord, y = image1$y_coord, label = label)
ggplot(data = image1_plot,aes(x = x, y = -y, color = label)) + geom_point() + scale_color_manual(values=c("white", "grey", "black"))
```

```{r}
label = image2$expert_label
label[label == 1] = "cloud"
label[label == -1] = "not cloud"
label[label == 0] = "unlabeled"
image2_plot = data.frame(x = image2$x_coord, y = image2$y_coord, label = label)
ggplot(data = image2_plot,aes(x = x, y = -y, color = label)) + geom_point() + scale_color_manual(values=c("white", "grey", "black"))
```
```{r}
label = image3$expert_label
label[label == 1] = "cloud"
label[label == -1] = "not cloud"
label[label == 0] = "unlabeled"
image3_plot = data.frame(x = image3$x_coord, y = image3$y_coord, label = label)
ggplot(data = image3_plot,aes(x = x, y = -y, color = label)) + geom_point() + scale_color_manual(values=c("white", "grey", "black"))
```
From the three plots, we can see the pattern that the pixels with same labels are connected to each other, and unmarked pixels stay around those marked as clouds. This pattern contradicts to our assumption that the samples are i.i.d., because the pixels adjcent to pixels marked as clouds are more likely to be marked as clouds.

* (c)
```{r}
# pairwise relationship between features for image1
features = data.frame(NDAI = image1$NDAI, SD = image1$SD, CORR = image1$CORR, DF = image1$DF, CF = image1$CF, BF = image1$BF, AF = image1$AF, AN = image1$AN)
pairs(features, gap = 0, pch = ".")
```
```{r}
# pairwise relationship between features for image3
features = data.frame(NDAI = image2$NDAI, SD = image2$SD, CORR = image2$CORR, DF = image2$DF, CF = image2$CF, BF = image2$BF, AF = image2$AF, AN = image2$AN)
pairs(features, gap = 0, pch = ".")
```
```{r}
# pairwise relationship between features for image3
features = data.frame(NDAI = image3$NDAI, SD = image3$SD, CORR = image3$CORR, DF = image3$DF, CF = image3$CF, BF = image3$BF, AF = image3$AF, AN = image3$AN)
pairs(features, gap = 0, pch = ".")
```
The three pairwise scatterplots all show that DF, CF, BF, AF and AN shows a linear relationship between each other, especially for AF and AN, AF and BF. However, we observe that data points in the third pairwise scatterplot spread more widely than in the first two pairwise sctterplots. The differences between three graphs can also show that the (linear) relationships decrease over time.

After checking pairwise relationship plots, we study the relationship between each independent featues and their expert labels for each image and all data combined.
```{r}
#relationship between expert label and NDAI image1
expert_NDAI = data.frame(label = as.character(image1$expert_label), CORR = image1$CORR)
expert_NDAI = expert_NDAI[which(expert_NDAI$label != "0"), ]
ggplot(data = expert_NDAI, aes(x = label, y = CORR, group = label, fill = label)) + geom_boxplot() + scale_fill_discrete(name = "Label", labels = c("not cloud", "cloud")) + ggtitle("Label vs. CORR image1")
```

```{r}
#relationship between expert label and NDAI image2
expert_NDAI = data.frame(label =  as.character(image2$expert_label), CORR = image2$CORR)
expert_NDAI = expert_NDAI[which(expert_NDAI$label != "0"), ]
ggplot(data = expert_NDAI, aes(x = label, y = CORR, group = label, fill = label)) + geom_boxplot() + scale_fill_discrete(name = "Label", labels = c("not cloud", "cloud")) + ggtitle("Label vs. CORR image2")
```
```{r}
#relationship between expert label and NDAI image2
expert_NDAI = data.frame(label =  as.character(image3$expert_label), CORR = image3$CORR)
expert_NDAI = expert_NDAI[which(expert_NDAI$label != "0"), ]
ggplot(data = expert_NDAI, aes(x = label, y = CORR, group = label, fill = label)) + geom_boxplot() + scale_fill_discrete(name = "Label", labels = c("not cloud", "cloud")) + ggtitle("Label vs. CORR image3")
```
```{r}
#relationship between expert label and NDAI image2
expert_NDAI = data.frame(label =  as.character(all$expert_label), CORR = all$CORR)
expert_NDAI = expert_NDAI[which(expert_NDAI$label != "0"), ]
ggplot(data = expert_NDAI, aes(x = label, y = CORR, group = label, fill = label)) + geom_boxplot() + scale_fill_discrete(name = "Label", labels = c("not cloud", "cloud")) + ggtitle("Label vs. CORR All Data")
```
The boxplots for CORR based on different labels show that CORR is on average higher for pixels marked as cloud than as not cloud. CORR also has a higher variance for those marked as cloud.

This conclusion contradicts to the statement in the paper that high correlations over cloud-free areas or low clouds are expected. This is because high correlations for clouds also occur under rare circumstances. More importantly, recklessly declare clear for high CORR pixels and cloudy for low CORR pixels will produce errors due to smoothness of surface terrain and the difference of attitudes of clouds.

Therefore, we should also involve the feature SD to identify surfaces into our investigation. We first plot SD vs. Label independently for each image and all data.
```{r}
expert_SD = data.frame(label = as.character(image1$expert_label), SD = image1$SD)
expert_SD = expert_SD[which(expert_SD$label != "0"), ]
ggplot(data = expert_SD, aes(x = label, y = SD, group = label, fill = label)) + geom_boxplot() + scale_fill_discrete(name = "Label", labels = c("not cloud", "cloud")) + ggtitle("Label vs. SD image1")
```
```{r}
expert_SD = data.frame(label = as.character(image2$expert_label), SD = image2$SD)
expert_SD = expert_SD[which(expert_SD$label != "0"), ]
ggplot(data = expert_SD, aes(x = label, y = SD, group = label, fill = label)) + geom_boxplot() + scale_fill_discrete(name = "Label", labels = c("not cloud", "cloud")) + ggtitle("Label vs. SD image2")
```
```{r}
expert_SD = data.frame(label = as.character(image3$expert_label), SD = image3$SD)
expert_SD = expert_SD[which(expert_SD$label != "0"), ]
ggplot(data = expert_SD, aes(x = label, y = SD, group = label, fill = label)) + geom_boxplot() + scale_fill_discrete(name = "Label", labels = c("not cloud", "cloud")) + ggtitle("Label vs. SD image3")
```
```{r}
expert_SD = data.frame(label = as.character(all$expert_label), SD = all$SD)
expert_SD = expert_SD[which(expert_SD$label != "0"), ]
ggplot(data = expert_SD, aes(x = label, y = SD, group = label, fill = label)) + geom_boxplot() + scale_fill_discrete(name = "Label", labels = c("not cloud", "cloud")) + ggtitle("Label vs. SD All Data")
```
From the boxplots for SD based on different labels, we can clearly see that the SD is higher for cloud pixels than those cloud-free ones. But the cloud-free pixels spread more widely. It can be explained that SD are usually small for radiation emanating from smooth surfaces.

Finally, the thrid feature NDAI relates to the differences for isoreopic level of surface-leaving radiation between low-attitude clouds and snow-coved surfaces.
```{r}
expert_NDAI = data.frame(label = as.character(image1$expert_label), NDAI = image1$NDAI)
expert_NDAI = expert_NDAI[which(expert_NDAI$label != "0"), ]
ggplot(data = expert_NDAI, aes(x = label, y = NDAI, group = label, fill = label)) + geom_boxplot() + scale_fill_discrete(name = "Label", labels = c("not cloud", "cloud")) + ggtitle("Label vs. NDAI image1")
```
```{r}
expert_NDAI = data.frame(label = as.character(image2$expert_label), NDAI = image2$NDAI)
expert_NDAI = expert_NDAI[which(expert_NDAI$label != "0"), ]
ggplot(data = expert_NDAI, aes(x = label, y = NDAI, group = label, fill = label)) + geom_boxplot() + scale_fill_discrete(name = "Label", labels = c("not cloud", "cloud")) + ggtitle("Label vs. NDAI image2")
```
```{r}
expert_NDAI = data.frame(label = as.character(image3$expert_label), NDAI = image3$NDAI)
expert_NDAI = expert_NDAI[which(expert_NDAI$label != "0"), ]
ggplot(data = expert_NDAI, aes(x = label, y = NDAI, group = label, fill = label)) + geom_boxplot() + scale_fill_discrete(name = "Label", labels = c("not cloud", "cloud")) + ggtitle("Label vs. NDAI image3")
```
```{r}
expert_NDAI = data.frame(label = as.character(all$expert_label), NDAI = all$NDAI)
expert_NDAI = expert_NDAI[which(expert_NDAI$label != "0"), ]
ggplot(data = expert_NDAI, aes(x = label, y = NDAI, group = label, fill = label)) + geom_boxplot() + scale_fill_discrete(name = "Label", labels = c("not cloud", "cloud")) + ggtitle("Label vs. NDAI All Data")
```

From the boxplots for NDAI based on different labels, we can clearly see that the NDAI is higher for cloud pixels than those cloud-free ones. The distrubition for cloud-free pixels are left skewed, while the distribution for pixels marked as cloud are roughly symmetric. The distribution for three different image data are roughly the same as well.

## Problem 2
* 2(a)
Since the three image data set represent the cloud dsitribution at different times at the same place. We decide not to combine all data into one. Since the data are not i.i.d., we cannot simply split the data by random. Our first method is, for each image data set, to divide all the data into 25 groups by cutting the image into 5*5 small images. For instance, data with y_coord from 2.0-78.2 and x_coord from 65.0-125.8 are in the same group. We randomly select 23 groups from these 25 groups as training/validation data and 2 groups as test data. In the 25 groups, we use cross validation to generate 5 validation data.
```{r}
min_x = min(image1$x_coord)
max_x = max(image1$x_coord)
min_y = min(image1$y_coord)
max_y = max(image1$y_coord)
det_x = (max_x - min_x) / 5
det_y = (max_y - min_y) / 5
x_cut = seq(min_x, max_x + 2, det_x)
y_cut = seq(min_y, max_y + 2, det_y)
x_cut[length(x_cut)] = x_cut[length(x_cut)] + 1
y_cut[length(y_cut)] = y_cut[length(y_cut)] + 1

train_val = sample(1:25, 23, replace = FALSE)
x_index = (train_val - 1) %/% 5 + 1
y_index = (train_val - 1) %% 5 + 1
train_val_data = image1
train_val_data$check = rep(FALSE, nrow(train_val_data))
for (i in 1:length(x_index)) {
  lower_x = x_cut[x_index[i]]
  upper_x = x_cut[x_index[i] + 1]
  lower_y = y_cut[y_index[i]]
  upper_y = y_cut[y_index[i] + 1]
  train_val_data[train_val_data$x_coord >= lower_x & train_val_data$x_coord < upper_x & train_val_data$y_coord >= lower_y & train_val_data$y_coord < upper_y, "check"] = TRUE
}
test_data = train_val_data[!train_val_data$check, ]
test_data = within(test_data, rm(check))
train_val_data = train_val_data[train_val_data$check, ]
train_val_data = within(train_val_data, rm(check))

x_train_index = sample(train_val, 18, replace = FALSE)
x_index = (x_train_index - 1) %/% 5 + 1
y_index = (x_train_index - 1) %% 5 + 1
train_data = train_val_data
train_data$check = rep(FALSE, nrow(train_data))
for (i in 1:length(x_index)) {
  lower_x = x_cut[x_index[i]]
  upper_x = x_cut[x_index[i] + 1]
  lower_y = y_cut[y_index[i]]
  upper_y = y_cut[y_index[i] + 1]
  train_data[train_data$x_coord >= lower_x & train_data$x_coord < upper_x & train_data$y_coord >= lower_y & train_data$y_coord < upper_y, "check"] = TRUE
}
validation_data = train_data[!train_data$check, ]
train_data = train_data[train_data$check, ]
```

```{r}
sum(test_data$expert_label == -1) / nrow(test_data)
sum(validation_data$expert_label == -1) / nrow(validation_data)
```
Setting all labels ti -1, the accuracy for test data is 0.377 and that for validation data is 0.386, which is relatively low. If the test data and validation data contain mostly -1, the trivial classifier will have a high average accuracy.

